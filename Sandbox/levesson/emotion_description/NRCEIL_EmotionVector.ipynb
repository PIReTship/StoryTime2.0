{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from spacy.lang.en import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Long stop words list using 3 differnt python stopword libraries\n",
    "stops = list(set(stopwords.words('english') + list(set(ENGLISH_STOP_WORDS)) + list(set(STOP_WORDS)) + [\"http\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This Block loads the Lexicon and creates a data structure for the emotion-itensity\n",
    "fileEmotion = \"emotion_itensity.txt\"\n",
    "table = pd.read_csv(fileEmotion,  names=[\"word\", \"emotion\", \"intensity\"], sep='\\t')\n",
    "lmtzr = WordNetLemmatizer()\n",
    "lemma_word = []\n",
    "pos = []\n",
    "for word in table.word:\n",
    "    pos_temp= get_wordnet_pos(word)\n",
    "    pos.append(pos_temp)\n",
    "    lemma_word.append(lmtzr.lemmatize(word, pos_temp))\n",
    "table['word'] = lemma_word\n",
    "table['pos'] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>outrage</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.964</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brutality</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.959</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hatred</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.953</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hateful</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.940</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>terrorize</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.939</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>fugitive</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.141</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9924</th>\n",
       "      <td>divorce</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.133</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9925</th>\n",
       "      <td>mistake</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.133</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>bait</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.133</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9927</th>\n",
       "      <td>scoundrel</td>\n",
       "      <td>trust</td>\n",
       "      <td>0.117</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9928 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word emotion  intensity pos\n",
       "0       outrage   anger      0.964   v\n",
       "1     brutality   anger      0.959   n\n",
       "2        hatred   anger      0.953   v\n",
       "3       hateful   anger      0.940   n\n",
       "4     terrorize   anger      0.939   v\n",
       "...         ...     ...        ...  ..\n",
       "9923   fugitive   trust      0.141   a\n",
       "9924    divorce   trust      0.133   n\n",
       "9925    mistake   trust      0.133   n\n",
       "9926       bait   trust      0.133   n\n",
       "9927  scoundrel   trust      0.117   n\n",
       "\n",
       "[9928 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = table.groupby(['word', 'pos', 'emotion'])['intensity'].mean().unstack('emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [i[0] for i in temp.index]\n",
    "pos = [i[1] for i in temp.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>suprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaaaaah</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaaah</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abacus</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandon</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandon</td>\n",
       "      <td>v</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5780</th>\n",
       "      <td>zany</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5781</th>\n",
       "      <td>zeal</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.328</td>\n",
       "      <td>1.859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5782</th>\n",
       "      <td>zealous</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5783</th>\n",
       "      <td>zen</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.515</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5784</th>\n",
       "      <td>zest</td>\n",
       "      <td>n</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.289</td>\n",
       "      <td>1.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5785 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word pos  anger  anticipation  disgust   fear    joy  sadness  \\\n",
       "0     aaaaaaah   n  0.000          0.00      0.0  0.344  0.000    0.000   \n",
       "1        aaaah   n  0.000          0.00      0.0  0.234  0.000    0.000   \n",
       "2       abacus   n  0.000          0.00      0.0  0.000  0.000    0.000   \n",
       "3      abandon   n  0.000          0.00      0.0  0.531  0.000    0.703   \n",
       "4      abandon   v  0.222          0.00      0.0  0.534  0.000    0.828   \n",
       "...        ...  ..    ...           ...      ...    ...    ...      ...   \n",
       "5780      zany   n  0.000          0.00      0.0  0.000  0.000    0.000   \n",
       "5781      zeal   n  0.000          0.50      0.0  0.000  0.547    0.000   \n",
       "5782   zealous   a  0.000          0.00      0.0  0.000  0.393    0.000   \n",
       "5783       zen   n  0.000          0.00      0.0  0.000  0.515    0.000   \n",
       "5784      zest   n  0.000          0.57      0.0  0.000  0.516    0.000   \n",
       "\n",
       "      suprise  trust    sum  \n",
       "0       0.000  0.000  0.344  \n",
       "1       0.000  0.000  0.234  \n",
       "2       0.000  0.406  0.406  \n",
       "3       0.000  0.000  1.234  \n",
       "4       0.000  0.000  1.584  \n",
       "...       ...    ...    ...  \n",
       "5780    0.555  0.000  0.555  \n",
       "5781    0.484  0.328  1.859  \n",
       "5782    0.000  0.258  0.651  \n",
       "5783    0.000  0.000  0.515  \n",
       "5784    0.000  0.289  1.375  \n",
       "\n",
       "[5785 rows x 11 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.DataFrame()\n",
    "new['word'] = words\n",
    "new['pos'] = pos\n",
    "new['anger'] = list(temp['anger'])\n",
    "new['anticipation'] = list(temp['anticipation'])\n",
    "new['disgust'] = list(temp['disgust'])\n",
    "new['fear'] = list(temp['fear'])\n",
    "new['joy'] = list(temp['joy'])\n",
    "new['sadness'] = list(temp['sadness'])\n",
    "new['suprise'] = list(temp['surprise'])\n",
    "new['trust'] = list(temp['trust'])\n",
    "new[\"sum\"] = new.sum(axis=1)\n",
    "new.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.to_csv('nrc_eil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()\n",
    "lemma_word = []\n",
    "pos = []\n",
    "for word in table.word:\n",
    "    pos_temp= get_wordnet_pos(word)\n",
    "    pos.append(pos_temp)\n",
    "    lemma_word.append(lmtzr.lemmatize(word, pos_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>emotion</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aaaaaaah</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaaah</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abacus</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>0.222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zany</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.555</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeal</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealous</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zen</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zest</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5980 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "emotion    anger  anticipation  disgust   fear    joy  sadness  surprise  \\\n",
       "word                                                                       \n",
       "aaaaaaah     NaN           NaN      NaN  0.344    NaN      NaN       NaN   \n",
       "aaaah        NaN           NaN      NaN  0.234    NaN      NaN       NaN   \n",
       "abacus       NaN           NaN      NaN    NaN    NaN      NaN       NaN   \n",
       "abandon      NaN           NaN      NaN  0.531    NaN    0.703       NaN   \n",
       "abandoned  0.222           NaN      NaN  0.534    NaN    0.828       NaN   \n",
       "...          ...           ...      ...    ...    ...      ...       ...   \n",
       "zany         NaN           NaN      NaN    NaN    NaN      NaN     0.555   \n",
       "zeal         NaN          0.50      NaN    NaN  0.547      NaN     0.484   \n",
       "zealous      NaN           NaN      NaN    NaN  0.393      NaN       NaN   \n",
       "zen          NaN           NaN      NaN    NaN  0.515      NaN       NaN   \n",
       "zest         NaN          0.57      NaN    NaN  0.516      NaN       NaN   \n",
       "\n",
       "emotion    trust  \n",
       "word              \n",
       "aaaaaaah     NaN  \n",
       "aaaah        NaN  \n",
       "abacus     0.406  \n",
       "abandon      NaN  \n",
       "abandoned    NaN  \n",
       "...          ...  \n",
       "zany         NaN  \n",
       "zeal       0.328  \n",
       "zealous    0.258  \n",
       "zen          NaN  \n",
       "zest       0.289  \n",
       "\n",
       "[5980 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.pivot(index='word', columns='emotion', values='intensity', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'None of [None] are in the columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3167920d1d1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgroup_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'emotion'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(self, index, columns, values)\u001b[0m\n\u001b[0;32m   5921\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5923\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5925\u001b[0m     _shared_docs[\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\u001b[0m in \u001b[0;36mpivot\u001b[1;34m(data, index, columns, values)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[0mappend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mindexed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   4301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4302\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4303\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4305\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'None of [None] are in the columns'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that get the emotion itensity\n",
    "def getEmotionItensity(word,emotion):\n",
    "    key = word + \"#\" + emotion\n",
    "    try:\n",
    "        return emotion_dic[key]\n",
    "    except:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the word is in the Lexicon\n",
    "def isWordInEmotionFile(word):\n",
    "    result = [(key) for key in emotion_dic.keys() if key.startswith(word + \"#\")]\n",
    "    if len(result) == 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stopping checker \n",
    "def isStopWord(word):\n",
    "    if word in stops:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign the emotion itensity to the dictionary\n",
    "def calculateEmotion(emotions, word):\n",
    "    emotions[\"Anger\"] += getEmotionItensity(word, \"anger\")\n",
    "    emotions[\"Anticipation\"] += getEmotionItensity(word, \"anticipation\")\n",
    "    emotions[\"Disgust\"] += getEmotionItensity(word, \"disgust\")\n",
    "    emotions[\"Fear\"] += getEmotionItensity(word, \"fear\")\n",
    "    emotions[\"Joy\"] += getEmotionItensity(word, \"joy\")\n",
    "    emotions[\"Sadness\"] += getEmotionItensity(word, \"sadness\")\n",
    "    emotions[\"Surprise\"] += getEmotionItensity(word, \"surprise\")\n",
    "    emotions[\"Trust\"] += getEmotionItensity(word, \"trust\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the emotion vector of a given text\n",
    "def getEmotionVector(text):\n",
    "    #create the initial emotions\n",
    "    emotions = {\"Anger\": 0.0,\n",
    "                \"Anticipation\": 0.0,\n",
    "                \"Disgust\": 0.0,\n",
    "                \"Fear\": 0.0,\n",
    "                \"Joy\": 0.0,\n",
    "                \"Sadness\": 0.0,\n",
    "                \"Surprise\": 0.0,\n",
    "                \"Trust\": 0.0,\n",
    "                \"Objective\": 0.0}\n",
    "    #parse the description\n",
    "    str = re.sub(\"[^a-zA-Z]+\", \" \", text)\n",
    "    pat = re.compile(r'[^a-zA-Z ]+')\n",
    "    str = re.sub(pat, '', str).lower()\n",
    "    #split string\n",
    "    splits = str.split()\n",
    "\n",
    "    #iterate over words array\n",
    "    for split in splits:\n",
    "        if not isStopWord(split):\n",
    "            #first check if the word is in its natural form\n",
    "            if isWordInEmotionFile(split): \n",
    "                calculateEmotion(emotions, split)\n",
    "            elif isWordInEmotionFile(lmtzr.lemmatize(split)):\n",
    "                calculateEmotion(emotions, lmtzr.lemmatize(split))\n",
    "            elif isWordInEmotionFile(lmtzr.lemmatize(split, 'v')):\n",
    "                calculateEmotion(emotions, lmtzr.lemmatize(split, 'v'))   \n",
    "            else:\n",
    "                emotions[\"Objective\"] += 1\n",
    "    total = sum(emotions.values())\n",
    "    for key in sorted(emotions.keys()):\n",
    "        try:\n",
    "            emotions[key] = (1.0 / total) * emotions[key]\n",
    "        except:\n",
    "            emotions[key] = 0\n",
    "    return emotions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getEmotionVector(\"Bob is happy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
